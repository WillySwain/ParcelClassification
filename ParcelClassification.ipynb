{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f79f28d",
   "metadata": {},
   "source": [
    "# Gather Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e546188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler\n",
    "import datetime\n",
    "def datetime2tuple(date):\n",
    "    return (date.year, date.month, date.day)\n",
    "def gather_data(n_total_images,n_per_crawl,keyword, folder_name):\n",
    "    delta = datetime.timedelta(days=30)\n",
    "    end_day = datetime.datetime(2023, 3, 17)\n",
    "    for i in range(int(n_total_images / n_per_crawl )):\n",
    "        start_day = end_day - delta\n",
    "        google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': folder_name})\n",
    "        google_crawler.crawl(keyword=keyword[i], filters={'date':(datetime2tuple(start_day), datetime2tuple(end_day))}, file_idx_offset=i*n_per_crawl , max_num=n_per_crawl)\n",
    "        end_day = start_day - datetime.timedelta(days=1)\n",
    "\n",
    "#gather_data(700,100,['packages ready to ship','packages about to be sent','cardboard boxes','packages','box packages','sealed packages','delivery cardboard package box'],'goodpackages')\n",
    "#gather_data(200,100,['ripped cardboard boxes','ripped packages'],'rippedpackages') #ripped\n",
    "#gather_data(200,100,['destroyed packages','damaged cardboard boxes'],'crushedpackages') #crushed\n",
    "#gather_data(200,100,['cardboard boxes with water damage','wet cardboard boxes'],'leakingpackages')#leaking\n",
    "#gather_data(200,100,['burned cardboard','charred cardboard'],'burnedpackages') # burned\n",
    "#gather_data(200,100,['cardboard recycling pile','broken down cardboard boxes'],'foldedpackages')#folded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "225642ca",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "becb3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1085 files [00:01, 813.42 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "import shutil\n",
    "import os\n",
    "input_folder = \"data\\startingdata\\\\\"\n",
    "output_folder = \"data\\\\split data\\\\\"\n",
    "splitfolders.ratio(input_folder, output=output_folder,\n",
    "                   seed=42, ratio=(.8, 0, .2))\n",
    "subsets = ['test\\\\', 'train\\\\']\n",
    "for subset in subsets:\n",
    "    output = output_folder+subset\n",
    "    destination = \"data\\\\split data\\\\\"+subset+\"\\\\badpackages\\\\\"\n",
    "    categories = ['burnedpackages', 'crushedpackages',\n",
    "                  'foldedpackages', 'leakingpackages', 'rippedpackages']\n",
    "    for category in categories:\n",
    "        source_folder = output + category\n",
    "        for file_name in os.listdir(source_folder):\n",
    "\n",
    "            if os.path.exists(destination + '\\\\' + file_name):\n",
    "                data = os.path.splitext(file_name)\n",
    "                only_name = data[0]\n",
    "                extension = data[1]\n",
    "                new_base = category + only_name + extension\n",
    "                new_name = os.path.join(destination, new_base)\n",
    "                shutil.move(source_folder + '\\\\' + file_name, new_name)\n",
    "            else:\n",
    "                shutil.move(source_folder + '\\\\' + file_name,\n",
    "                            destination + '\\\\' + file_name)\n",
    "        os.rmdir(source_folder)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f98331f4",
   "metadata": {},
   "source": [
    "# Formatting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4bbcabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input,decode_predictions,ResNet50\n",
    "from tensorflow.keras.layers import Conv2D,Dense, Flatten,MaxPool2D,BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "img_height,img_width = (224,224)\n",
    "batch_size = 32\n",
    "\n",
    "train_data_path = \"data/split data/train/\"\n",
    "test_data_path = \"data/split data/test/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33af2f10",
   "metadata": {},
   "source": [
    "# Prep the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0628a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 520 images belonging to 2 classes.\n",
      "Found 87 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,shear_range=.2,zoom_range=0.2,horizontal_flip=True,validation_split=0.4) #might not need validation split\n",
    "training_data_generator = training_datagen.flow_from_directory(train_data_path,target_size=(img_height,img_width),batch_size=batch_size,class_mode='categorical',subset='training')\n",
    "testing_data_generator = training_datagen.flow_from_directory(test_data_path,target_size=(img_height,img_width),batch_size=1,class_mode='categorical',subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d779234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willi\\anaconda3\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 32s 2s/step - loss: 1.3760 - accuracy: 0.6827\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.6508 - accuracy: 0.7769\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.3468 - accuracy: 0.8346\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.2308 - accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.2133 - accuracy: 0.9077\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 28s 2s/step - loss: 0.1538 - accuracy: 0.9308\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 31s 2s/step - loss: 0.1622 - accuracy: 0.9385\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 30s 2s/step - loss: 0.1021 - accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 29s 2s/step - loss: 0.0827 - accuracy: 0.9731\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 27s 2s/step - loss: 0.0862 - accuracy: 0.9692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3a4c17e50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "base_model = ResNet50(include_top=False,weights='imagenet')\n",
    "output=base_model.output\n",
    "output=GlobalAveragePooling2D()(output)\n",
    "output=Dense(1024,activation='relu')(output)\n",
    "predictions = Dense(training_data_generator.num_classes,activation='softmax')(output)\n",
    "model = Model(inputs=base_model.input,outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(training_data_generator,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d88deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Models\\\\Resnet50\\\\Resnet50_with_50_10_datasplit.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "644fba3b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ac81710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 - 8s - loss: 0.5356 - accuracy: 0.7931 - 8s/epoch - 88ms/step\n",
      "0.7931034564971924\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = model.evaluate(testing_data_generator,verbose=2)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e16e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
