{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f79f28d",
   "metadata": {},
   "source": [
    "# Gather Dataset\n",
    "The dataset will be gathered using Google's iCrawler, all code below by William"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e546188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 15:58:59,328 - INFO - icrawler.crawler - start crawling...\n",
      "2023-04-23 15:58:59,328 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2023-04-23 15:58:59,329 - INFO - feeder - thread feeder-001 exit\n",
      "2023-04-23 15:58:59,330 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2023-04-23 15:58:59,332 - INFO - icrawler.crawler - starting 4 downloader threads...\n",
      "2023-04-23 15:59:00,359 - INFO - parser - parsing result page https://www.google.com/search?q=crushed+boxes&ijn=0&start=0&tbs=cdr%3A1%2Ccd_min%3A02%2F15%2F2023%2Ccd_max%3A03%2F17%2F2023&tbm=isch\n",
      "2023-04-23 15:59:00,535 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1165557816/photo/cardboard-boxes.jpg\n",
      "2023-04-23 15:59:00,586 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1215484506/photo/crumpled-cardboard-mail-box.jpg\n",
      "2023-04-23 15:59:00,593 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/664274592/photo/damaged-cardboard-box.jpg\n",
      "2023-04-23 15:59:00,603 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/512045270/photo/isolated-shot-of-crushed-cardboard-box-on-white-background.jpg\n",
      "2023-04-23 15:59:00,612 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/520800288/photo/isolated-shot-of-crushed-cardboard-box-on-white-background.jpg\n",
      "2023-04-23 15:59:00,624 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/464917940/photo/crushed-cardboard-box.jpg\n",
      "2023-04-23 15:59:00,635 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/522329421/photo/cardboard-box-collection.jpg\n",
      "2023-04-23 15:59:00,692 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/172697414/photo/a-smashed-box-with-fragile-tape-all-around-it.jpg\n",
      "2023-04-23 15:59:00,791 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/510694525/photo/box-damaged-in-shipping.jpg\n",
      "2023-04-23 15:59:00,990 - INFO - downloader - image #1\thttps://thumbs.dreamstime.com/z/crushed-box-fragile-tape-13095901.jpg\n",
      "2023-04-23 15:59:00,990 - INFO - downloader - image #2\thttps://www.shutterstock.com/image-photo/fragile-brown-box-crushed-xxxl-260nw-124068139.jpg\n",
      "2023-04-23 15:59:01,015 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/512044912/photo/isolated-shot-of-crushed-cardboard-box-on-white-background.jpg\n",
      "2023-04-23 15:59:01,099 - INFO - downloader - image #3\thttps://thumbs.dreamstime.com/z/man-crushed-underneath-cardboard-boxes-man-crushed-underneath-cardboard-boxes-was-carrying-heavy-shopping-burden-concept-102809448.jpg\n",
      "2023-04-23 15:59:01,114 - INFO - downloader - image #4\thttps://www.gbpdirect.com/wp-content/uploads/2017/10/crushed-boxes.jpg\n",
      "2023-04-23 15:59:01,216 - INFO - downloader - image #5\thttps://www.shutterstock.com/image-photo/damaged-cardboard-box-isolated-on-260nw-580675549.jpg\n",
      "2023-04-23 15:59:01,270 - INFO - downloader - image #6\thttps://c8.alamy.com/comp/JH36MX/a-crushed-and-damaged-amazon-box-JH36MX.jpg\n",
      "2023-04-23 15:59:01,409 - INFO - downloader - image #7\thttps://www.shutterstock.com/image-photo/damaged-cardboard-box-isolated-on-260nw-1670322052.jpg\n",
      "2023-04-23 15:59:01,476 - INFO - downloader - image #8\thttps://previews.123rf.com/images/whitestar1955/whitestar19551910/whitestar1955191000079/137142490-vertical-shot-of-four-stacked-do-not-crush-boxes-crushed-isolated-on-white.jpg\n",
      "2023-04-23 15:59:01,550 - INFO - downloader - image #9\thttps://c8.alamy.com/comp/2J4675M/crushed-cardboard-box-cut-out-on-white-2J4675M.jpg\n",
      "2023-04-23 15:59:01,570 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1141711878/photo/cardboard-boxes.jpg\n",
      "2023-04-23 15:59:01,702 - INFO - downloader - image #10\thttps://pages.hep.wisc.edu/~wsmith/cms/shipping2.jpg\n",
      "2023-04-23 15:59:01,776 - INFO - downloader - image #11\thttps://c8.alamy.com/comp/CW8RFT/a-crushed-cardboard-box-that-was-marked-as-being-fragile-studio-shot-CW8RFT.jpg\n",
      "2023-04-23 15:59:01,804 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1201162916/photo/torn-hole-in-the-wall-of-a-cardboard-post-box.jpg\n",
      "2023-04-23 15:59:01,915 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1314728736/photo/crushed-package.jpg\n",
      "2023-04-23 15:59:01,929 - INFO - downloader - image #12\thttps://3.bp.blogspot.com/-93wH0tDgdQI/Vyls_X1hsAI/AAAAAAAACjo/g0uZg8wy00s3ZrUBBXuMMINsiNcB1DNPQCLcB/s640/crushed%2Bbox.jpg\n",
      "2023-04-23 15:59:02,001 - INFO - downloader - image #13\thttps://img.freepik.com/premium-vector/cartoon-damaged-torn-wet-cardboard-delivery-boxes-piles-crumpled-crushed-cargo-carton-package-parcels-bad-shipping-vector-set_102902-5351.jpg\n",
      "2023-04-23 15:59:02,014 - INFO - downloader - image #14\thttps://thumbs.dreamstime.com/z/crushed-fragile-box-cardboard-handle-care-printed-white-background-53807125.jpg\n",
      "2023-04-23 15:59:02,018 - INFO - downloader - image #15\thttps://pages.hep.wisc.edu/~wsmith/cms/shipping3.jpg\n",
      "2023-04-23 15:59:02,092 - INFO - downloader - image #16\thttps://live.staticflickr.com/70/191808749_95d492dd53_b.jpg\n",
      "2023-04-23 15:59:02,135 - INFO - downloader - image #17\thttps://m.media-amazon.com/images/I/51uR-U0MfRL.jpg\n",
      "2023-04-23 15:59:02,143 - INFO - downloader - image #18\thttps://m.media-amazon.com/images/I/61kg6FrFwzL.jpg\n",
      "2023-04-23 15:59:02,162 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1176223026/photo/delivery-box-damaged-in-shipping.jpg\n",
      "2023-04-23 15:59:02,172 - INFO - downloader - image #19\thttps://m.media-amazon.com/images/I/71xC1O0gpeL._AC_UF894,1000_QL80_.jpg\n",
      "2023-04-23 15:59:02,188 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1387234238/vector/damaged-carton-cardboard-boxes-crumpled-delivery-package-broken-wet-torn-carton-delivery.jpg\n",
      "2023-04-23 15:59:02,218 - INFO - downloader - image #20\thttps://thumbs.dreamstime.com/z/man-crushed-underneath-cardboard-boxes-was-carrying-heavy-shopping-burden-concept-97905683.jpg\n",
      "2023-04-23 15:59:02,241 - INFO - downloader - image #21\thttps://m.media-amazon.com/images/I/61PSvqHdM2L._AC_UF1000,1000_QL80_.jpg\n",
      "2023-04-23 15:59:02,267 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/6551-000350/photo/damaged-package.jpg\n",
      "2023-04-23 15:59:02,359 - INFO - downloader - image #22\thttps://pages.hep.wisc.edu/~wsmith/cms/shipping4.jpg\n",
      "2023-04-23 15:59:02,362 - INFO - downloader - image #23\thttps://live.staticflickr.com/8546/29382829314_0d3fd7c77e_b.jpg\n",
      "2023-04-23 15:59:02,540 - INFO - downloader - image #24\thttps://www.shutterstock.com/image-vector/cardboard-box-packing-note-260nw-270114800.jpg\n",
      "2023-04-23 15:59:02,700 - INFO - downloader - image #25\thttps://st4.depositphotos.com/1911991/31557/i/1600/depositphotos_315578772-stock-photo-crushed-shipping-boxes-isolated-on.jpg\n",
      "2023-04-23 15:59:02,701 - INFO - downloader - image #26\thttps://i.redd.it/86zkfxl3sck21.jpg\n",
      "2023-04-23 15:59:02,732 - INFO - downloader - image #27\thttps://m.media-amazon.com/images/I/51zkHNc8PPL.jpg\n",
      "2023-04-23 15:59:02,852 - INFO - downloader - image #28\thttps://m.media-amazon.com/images/I/71dmzphgdXL._AC_UF1000,1000_QL80_.jpg\n",
      "2023-04-23 15:59:02,894 - INFO - downloader - image #29\thttps://www.shutterstock.com/image-photo/asian-delivery-man-blue-uniform-260nw-1902445204.jpg\n",
      "2023-04-23 15:59:02,910 - INFO - downloader - image #30\thttps://previews.123rf.com/images/timhester/timhester1903/timhester190300070/119545243-crushed-and-damaged-isometric-vector-cardboard-packaging-box-with-broken-tape.jpg\n",
      "2023-04-23 15:59:02,950 - INFO - downloader - image #31\thttps://thumbs.dreamstime.com/z/crushed-do-not-crush-boxes-isolated-white-horizontal-shot-five-stacked-cardboard-destroyed-shipping-despite-being-162083029.jpg\n",
      "2023-04-23 15:59:02,988 - INFO - downloader - image #32\thttps://gbepackaging.com/media/cms/articlestash/Recycled-Boxes-Crushed-4_544.jpg\n",
      "2023-04-23 15:59:03,242 - INFO - downloader - image #33\thttps://cdn-ehnkl.nitrocdn.com/lVEbTCCcoGiFfrHuGsTAksuylpdaUoor/assets/static/optimized/wp-content/uploads/2019/09/3440e6fc2ffc0a9a34586fc7b7759aa8.Crush-Bottom-Boxes-03.jpg\n",
      "2023-04-23 15:59:03,336 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1330565927/vector/damaged-box-cartoon-broken-package-ripped-and-wet-shipping-cardboard-packaging-cargo-and.jpg\n",
      "2023-04-23 15:59:03,357 - INFO - downloader - image #34\thttps://img.freepik.com/premium-vector/crushed-orange-little-drink-box-isolated-white-background_691771-152.jpg\n",
      "2023-04-23 15:59:03,435 - ERROR - downloader - Response status code 403, file https://preview.redd.it/tb2isr684sg41.png\n",
      "2023-04-23 15:59:03,512 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1290314509/photo/crushed-cardboard-box-parcel-with-a-spanish-language-fragile-handle-with-care-label.jpg\n",
      "2023-04-23 15:59:03,528 - INFO - downloader - image #35\thttps://thumbs.dreamstime.com/b/damaged-box-crush-containers-poor-quality-cardboard-packages-delivery-problems-vector-pictures-set-isolated-illustrations-251632981.jpg\n",
      "2023-04-23 15:59:03,536 - INFO - downloader - image #36\thttps://c8.alamy.com/comp/2HGDWPR/cartoon-damaged-torn-and-wet-cardboard-delivery-boxes-and-piles-crumpled-crushed-cargo-carton-package-and-parcels-bad-shipping-vector-set-2HGDWPR.jpg\n",
      "2023-04-23 15:59:03,540 - INFO - downloader - image #37\thttps://www.shutterstock.com/image-photo/damaged-cardboard-box-on-white-260nw-1923722210.jpg\n",
      "2023-04-23 15:59:03,555 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/81981403/photo/a-crushed-cardboard-box.jpg\n",
      "2023-04-23 15:59:03,568 - INFO - downloader - image #38\thttps://thumbs.dreamstime.com/z/crushed-underneath-6401440.jpg\n",
      "2023-04-23 15:59:03,631 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/182467728/photo/packing-boxes-before-and-after.jpg\n",
      "2023-04-23 15:59:03,668 - INFO - downloader - image #39\thttps://c8.alamy.com/comp/BER70E/crushed-and-burned-cardboard-box-with-hole-BER70E.jpg\n",
      "2023-04-23 15:59:03,724 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/182898294/photo/damaged-fragile-parcel.jpg\n",
      "2023-04-23 15:59:03,759 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/sb10063216g-001/photo/man-crushing-cardboard-box-with-foot-low-section.jpg\n",
      "2023-04-23 15:59:03,810 - INFO - downloader - image #40\thttps://i.ebayimg.com/images/g/LIYAAOSwVgFfI5Gc/s-l1600.jpg\n",
      "2023-04-23 15:59:03,834 - INFO - downloader - image #41\thttps://thumbs.dreamstime.com/b/damaged-cardboard-boxes-crumpled-brown-bag-storage-retail-logistics-delivery-concept-cartoon-broken-package-wrinkled-267733375.jpg\n",
      "2023-04-23 15:59:03,858 - INFO - downloader - image #42\thttps://cdn-ehnkl.nitrocdn.com/lVEbTCCcoGiFfrHuGsTAksuylpdaUoor/assets/static/optimized/wp-content/uploads/2019/09/b027a1a21fd13dc423221224c8504019.Crush-Bottom-Boxes-04.jpg\n",
      "2023-04-23 15:59:03,942 - INFO - downloader - image #43\thttps://www.shutterstock.com/image-vector/crushed-cardboard-box-falling-bruised-260nw-2255423281.jpg\n",
      "2023-04-23 15:59:04,033 - INFO - downloader - image #44\thttps://st3.depositphotos.com/29384342/33870/i/1600/depositphotos_338706472-stock-photo-isolated-white-background-cardboard-box.jpg\n",
      "2023-04-23 15:59:04,054 - INFO - downloader - image #45\thttps://cdn.vectorstock.com/i/preview-1x/93/28/damaged-torn-box-rumpled-spoiled-delivery-parcel-vector-46499328.jpg\n",
      "2023-04-23 15:59:04,107 - INFO - downloader - image #46\thttps://st3.depositphotos.com/1177973/17094/i/600/depositphotos_170945606-stock-photo-paper-garbage-on-white-background.jpg\n",
      "2023-04-23 15:59:04,196 - INFO - downloader - image #47\thttps://cdn-ehnkl.nitrocdn.com/lVEbTCCcoGiFfrHuGsTAksuylpdaUoor/assets/static/optimized/wp-content/uploads/2019/09/06e39b2f863d2bafe4fefd657bacccf6.Crush-Bottom-Boxes-01.jpg\n",
      "2023-04-23 15:59:04,206 - INFO - downloader - image #48\thttps://thumbs.dreamstime.com/b/damage-package-d-271665452.jpg\n",
      "2023-04-23 15:59:04,294 - INFO - downloader - image #49\thttps://st3.depositphotos.com/1521357/15792/i/1600/depositphotos_157925740-stock-photo-damaged-cardboard-box.jpg\n",
      "2023-04-23 15:59:04,298 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/520799946/photo/isolated-shot-of-crushed-cardboard-box-on-white-background.jpg\n",
      "2023-04-23 15:59:04,315 - INFO - downloader - image #50\thttps://media.smallbiztrends.com/2022/04/Aviditi-White-Corrugated-Corrugated-Cardboard-Mailing-Boxes.png\n",
      "2023-04-23 15:59:04,395 - INFO - downloader - image #51\thttps://thumbs.dreamstime.com/b/crumpled-cardboard-box-corrugated-sides-as-packaging-shipping-container-vector-set-rumpled-industrial-brown-paperboard-259157197.jpg\n",
      "2023-04-23 15:59:04,416 - INFO - downloader - image #52\thttps://www.shutterstock.com/image-vector/damaged-broken-crumpled-box-vector-260nw-2255422701.jpg\n",
      "2023-04-23 15:59:04,760 - INFO - downloader - image #53\thttps://www.chefstore.com/images/usf_items/8327272/8327272.jpg\n",
      "2023-04-23 15:59:04,783 - INFO - downloader - image #54\thttps://packagingguruji.com/wp-content/uploads/2019/01/CFB.jpg\n",
      "2023-04-23 15:59:05,073 - INFO - downloader - image #55\thttps://www.foodservicedirect.com/media/catalog/product/1/0/10089424200361_2_rhkeod9xl2ezcb8c.jpg\n",
      "2023-04-23 15:59:05,119 - INFO - downloader - image #56\thttps://cdn.shopify.com/s/files/1/0620/4512/6834/products/avct8uhwpu9pitnleacu.jpg\n",
      "2023-04-23 15:59:05,127 - INFO - downloader - image #57\thttps://www.bcpkg.com/Content/CategoryImages/Full/2510.jpg\n",
      "2023-04-23 15:59:05,157 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/87400363/photo/boys-jumping-on-boxes.jpg\n",
      "2023-04-23 15:59:05,243 - ERROR - downloader - Response status code 400, file https://media.istockphoto.com/id/1365121637/photo/shards-of-broken-dishes-in-a-crumpled-cardboard-box.jpg\n",
      "2023-04-23 15:59:05,247 - INFO - downloader - image #58\thttps://www.shutterstock.com/image-vector/crumpled-empty-cardboard-box-icon-260nw-539487427.jpg\n",
      "2023-04-23 15:59:05,419 - INFO - downloader - image #59\thttps://c8.alamy.com/comp/2A6CTAC/horizontal-shot-of-five-fragile-boxes-crushed-in-shipping-isolated-on-white-2A6CTAC.jpg\n",
      "2023-04-23 15:59:05,518 - INFO - downloader - image #60\thttps://cdn-ehnkl.nitrocdn.com/lVEbTCCcoGiFfrHuGsTAksuylpdaUoor/assets/static/optimized/wp-content/uploads/2019/09/ab0f5ab882cc45cb95ac40b32bcfe1ea.Crush-Bottom-Boxes-02.jpg\n",
      "2023-04-23 15:59:05,645 - INFO - downloader - image #61\thttps://cdn.shopify.com/s/files/1/0620/4512/6834/products/j6kbfuapbgfweb0smhpu.jpg\n",
      "2023-04-23 15:59:06,076 - INFO - downloader - image #62\thttps://www.ctvnews.ca/polopoly_fs/1.4482297.1561496741!/httpImage/image.jpg\n",
      "2023-04-23 15:59:07,083 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2023-04-23 15:59:07,084 - INFO - parser - thread parser-001 exit\n",
      "2023-04-23 15:59:10,431 - INFO - downloader - no more download task for thread downloader-001\n",
      "2023-04-23 15:59:10,431 - INFO - downloader - thread downloader-001 exit\n",
      "2023-04-23 15:59:10,526 - INFO - downloader - no more download task for thread downloader-002\n",
      "2023-04-23 15:59:10,526 - INFO - downloader - thread downloader-002 exit\n",
      "2023-04-23 15:59:10,650 - INFO - downloader - no more download task for thread downloader-004\n",
      "2023-04-23 15:59:10,650 - INFO - downloader - thread downloader-004 exit\n",
      "2023-04-23 15:59:11,089 - INFO - downloader - no more download task for thread downloader-003\n",
      "2023-04-23 15:59:11,089 - INFO - downloader - thread downloader-003 exit\n",
      "2023-04-23 15:59:11,445 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willi\\PycharmProjects\\ParcelClassification\\ParcelClassification.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         end_day \u001b[39m=\u001b[39m start_day \u001b[39m-\u001b[39m datetime\u001b[39m.\u001b[39mtimedelta(days\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#each call gathers data from the query and sends it to its respective directory to be manually cleaned\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#gather_data(900,100,['cardboard boxes with tape on it','cardboard boxes with tape on it','packages ready to ship','packages about to be sent','cardboard boxes',\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#           'packages','box packages','sealed packages','delivery cardboard package box'],'data/startingdata/goodpackages')\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m gather_data(\u001b[39m200\u001b[39;49m,\u001b[39m100\u001b[39;49m,[\u001b[39m'\u001b[39;49m\u001b[39mcrushed boxes\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mdata/startingdata/forshow\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\willi\\PycharmProjects\\ParcelClassification\\ParcelClassification.ipynb Cell 2\u001b[0m in \u001b[0;36mgather_data\u001b[1;34m(n_total_images, n_per_crawl, keyword, folder_name)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m start_day \u001b[39m=\u001b[39m end_day \u001b[39m-\u001b[39m delta\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m google_crawler \u001b[39m=\u001b[39m GoogleImageCrawler(downloader_threads\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, storage\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mroot_dir\u001b[39m\u001b[39m'\u001b[39m: folder_name})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m google_crawler\u001b[39m.\u001b[39mcrawl(keyword\u001b[39m=\u001b[39mkeyword[i], filters\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m:(datetime2tuple(start_day), datetime2tuple(end_day))}, file_idx_offset\u001b[39m=\u001b[39mi\u001b[39m*\u001b[39mn_per_crawl , max_num\u001b[39m=\u001b[39mn_per_crawl)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m end_day \u001b[39m=\u001b[39m start_day \u001b[39m-\u001b[39m datetime\u001b[39m.\u001b[39mtimedelta(days\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler\n",
    "import datetime\n",
    "def datetime2tuple(date):\n",
    "    return (date.year, date.month, date.day)\n",
    "def gather_data(n_total_images,n_per_crawl,keyword, folder_name): #collects data by sending google different search queries with different date constraints to mitigate duplicate images\n",
    "    delta = datetime.timedelta(days=30)\n",
    "    end_day = datetime.datetime(2023, 3, 17)\n",
    "    for i in range(int(n_total_images / n_per_crawl )):\n",
    "        start_day = end_day - delta\n",
    "        google_crawler = GoogleImageCrawler(downloader_threads=4, storage={'root_dir': folder_name})\n",
    "        google_crawler.crawl(keyword=keyword[i], filters={'date':(datetime2tuple(start_day), datetime2tuple(end_day))}, file_idx_offset=i*n_per_crawl , max_num=n_per_crawl)\n",
    "        end_day = start_day - datetime.timedelta(days=1)\n",
    "\n",
    "#each call gathers data from the query and sends it to its respective directory to be manually cleaned\n",
    "\n",
    "#gather_data(900,100,['cardboard boxes with tape on it','cardboard boxes with tape on it','packages ready to ship','packages about to be sent','cardboard boxes',\n",
    "#           'packages','box packages','sealed packages','delivery cardboard package box'],'data/startingdata/goodpackages')\n",
    "#gather_data(200,100,['ripped cardboard boxes','ripped packages'],'data/startingdata/rippedpackages') #ripped\n",
    "#gather_data(200,100,['destroyed packages','damaged cardboard boxes'],'data/startingdata/crushedpackages') #crushed\n",
    "#gather_data(200,100,['cardboard boxes with water damage','wet cardboard boxes'],'data/startingdata/leakingpackages')#leaking\n",
    "#gather_data(200,100,['burned cardboard','charred cardboard'],'data/startingdata/burnedpackages') # burned\n",
    "#gather_data(200,100,['cardboard recycling pile','broken down cardboard boxes'],'data/startingdata/foldedpackages')#folded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c919911c",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "225642ca",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "After manually cleaning the data, it is ready to be split into testing and training sets.\n",
    "The different categories of data will be merged into \"bad packages\" to allow for binary image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "becb3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1000 files [00:01, 710.18 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "import shutil\n",
    "import os\n",
    "input_folder = \"data\\\\startingdata\\\\\"\n",
    "output_folder = \"data\\\\split data\\\\\"\n",
    "splitfolders.ratio(input_folder, output=output_folder, #splits the data 80% for training and 20% for testing\n",
    "                   seed=2, ratio=(.6, .2, .2))\n",
    "subsets = ['test\\\\', 'train\\\\','val\\\\'] \n",
    "for subset in subsets: #will be moving images for the training and testing sets\n",
    "    output = output_folder+subset\n",
    "    destination = \"data\\\\split data\\\\\"+subset+\"\\\\badpackages\\\\\"\n",
    "    categories = ['burnedpackages', 'crushedpackages',\n",
    "                  'foldedpackages', 'leakingpackages', 'rippedpackages']\n",
    "    for category in categories: #will merge each directory of bad packages into a single one\n",
    "        source_folder = output + category\n",
    "        for file_name in os.listdir(source_folder):\n",
    "\n",
    "            if os.path.exists(destination + '\\\\' + file_name): #if the already path exists, it renames the new image and moves it\n",
    "                data = os.path.splitext(file_name)\n",
    "                only_name = data[0]\n",
    "                extension = data[1]\n",
    "                new_base = category + only_name + extension\n",
    "                new_name = os.path.join(destination, new_base)\n",
    "                shutil.move(source_folder + '\\\\' + file_name, new_name)\n",
    "            else:\n",
    "                shutil.move(source_folder + '\\\\' + file_name, #if the path is not already used, the new file will take its place\n",
    "                            destination + '\\\\' + file_name)\n",
    "        os.rmdir(source_folder)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f98331f4",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "The data will be preprocessed using Keras' ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bbcabae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input,ResNet50\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "img_height,img_width = (224,224) #the size required by resnet\n",
    "\n",
    "train_data_path = \"data/split data/train/\"\n",
    "test_data_path = \"data/split data/test/\"\n",
    "val_data_path = \"data/split data/val/\"\n",
    "training_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip=True,validation_split=0.4) #randomly flips images and saves 40% for validation\n",
    "training_data_generator = training_datagen.flow_from_directory(train_data_path,target_size=(img_height,img_width),class_mode='categorical',subset='training')\n",
    "testing_data_generator = training_datagen.flow_from_directory(test_data_path,target_size=(img_height,img_width),batch_size=1,class_mode='categorical',subset='validation')\n",
    "validation_data_generator = training_datagen.flow_from_directory(val_data_path,target_size=(img_height,img_width),batch_size=1,class_mode='categorical',subset='validation')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4df0abdb",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d779234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/15 [=======================>......] - ETA: 5s - loss: 0.9950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willi\\anaconda3\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 47s 3s/step - loss: 0.9020 - val_loss: 0.4561\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 39s 3s/step - loss: 0.2446 - val_loss: 0.3041\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 40s 3s/step - loss: 0.1391 - val_loss: 0.3434\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 39s 3s/step - loss: 0.0846 - val_loss: 0.4065\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 40s 3s/step - loss: 0.0647 - val_loss: 0.4214\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 39s 3s/step - loss: 0.0532 - val_loss: 0.3254\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 40s 3s/step - loss: 0.0389 - val_loss: 0.4006\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 43s 3s/step - loss: 0.0220 - val_loss: 0.3531\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 41s 3s/step - loss: 0.0220 - val_loss: 0.4017\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 40s 3s/step - loss: 0.0193 - val_loss: 0.4441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b73c45250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #This is required to get around an error thrown by larger images\n",
    "\n",
    "base_model = ResNet50(include_top=False,weights='imagenet')\n",
    "\n",
    "output=base_model.output #add new layers to the model\n",
    "output=GlobalAveragePooling2D()(output) #adds global average poolinglayer\n",
    "output=Dense(1024,activation='relu')(output)  #adds dense layer\n",
    "predictions = Dense(training_data_generator.num_classes,activation='softmax')(output)\n",
    "model = Model(inputs=base_model.input,outputs=predictions) \n",
    "\n",
    "for layer in base_model.layers: #freezes all of the weights in the base_model layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy') \n",
    "model.fit(training_data_generator,epochs=10,validation_data = validation_data_generator) # trains the newly added layers [] learning rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "644fba3b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3e16e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n"
     ]
    }
   ],
   "source": [
    "samples = len(testing_data_generator)\n",
    "predicted = []\n",
    "actual=[]\n",
    "#print(testing_data_generator.class_indices)\n",
    "for i in range(samples): #runs each sample in the test set\n",
    "    x,y=testing_data_generator.next() #x is the image and y is the label\n",
    "    predicted.append((model.predict(x)))\n",
    "    actual.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5bc696a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Precision: 0.875\n",
      "Recall: 0.9\n",
      "Specificity: 0.7857142857142857\n",
      "F1-Score: 0.8873239436619719\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#model.save('Models\\\\Resnet50\\\\Resnet50_with_50_10_datasplit.h5')\n",
    "predicted_class = [i.argmax() for i in predicted]\n",
    "actual_class = [i.argmax() for i in actual]\n",
    "\n",
    "conf_matrix = confusion_matrix(actual_class, predicted_class) #creates confusion matrix from predictions and actuals\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Actual label', fontsize=18)\n",
    "plt.ylabel('Predicted label', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "precision = (conf_matrix[0][0])/(conf_matrix[0][0]+conf_matrix[0][1])\n",
    "recall = (conf_matrix[0][0])/(conf_matrix[0][0]+conf_matrix[1][0])\n",
    "\n",
    "print(\"Accuracy:\",  (conf_matrix[0][0]+conf_matrix[1][1])/((conf_matrix[0][0]+conf_matrix[0][1])+(conf_matrix[1][0]+conf_matrix[1][1])))\n",
    "print(\"Precision:\",  precision)\n",
    "print(\"Recall:\",  recall)\n",
    "print(\"Specificity:\",  (conf_matrix[1][1])/(conf_matrix[1][1]+conf_matrix[0][1]))\n",
    "print(\"F1-Score:\",  (2*precision * recall)/(precision+recall))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dd5c455",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abccfc6e",
   "metadata": {},
   "source": [
    "## Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133c07c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n",
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import preprocess_input,VGG19\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "img_height,img_width = (224,224) #the size required by resnet\n",
    "\n",
    "train_data_path = \"data/split data/train/\"\n",
    "test_data_path = \"data/split data/test/\"\n",
    "val_data_path = \"data/split data/val/\"\n",
    "\n",
    "VGG_training_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip=True,validation_split=0.4) #randomly flips images and saves 40% for validation\n",
    "VGG_training_data_generator = VGG_training_datagen.flow_from_directory(train_data_path,target_size=(img_height,img_width),class_mode='categorical',subset='training')\n",
    "VGG_testing_data_generator = VGG_training_datagen.flow_from_directory(test_data_path,target_size=(img_height,img_width),batch_size=1,class_mode='categorical',subset='validation')\n",
    "VGG_validation_data_generator = VGG_training_datagen.flow_from_directory(val_data_path,target_size=(img_height,img_width),batch_size=1,class_mode='categorical',subset='validation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed0ef457",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8bf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/15 [===========>..................] - ETA: 36s - loss: 1.9442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willi\\anaconda3\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 82s 5s/step - loss: 1.5381 - val_loss: 0.5038\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 77s 5s/step - loss: 0.5237 - val_loss: 0.5295\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 78s 5s/step - loss: 0.1528 - val_loss: 0.3713\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 77s 5s/step - loss: 0.0745 - val_loss: 0.2804\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 80s 5s/step - loss: 0.0641 - val_loss: 0.2946\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 80s 5s/step - loss: 0.0576 - val_loss: 0.2987\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 81s 5s/step - loss: 0.0216 - val_loss: 0.2914\n",
      "Epoch 8/10\n",
      " 9/15 [=================>............] - ETA: 59s - loss: 0.0179 "
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True #This is required to get around an error thrown by larger images\n",
    "\n",
    "base_model = VGG19(include_top=False,weights='imagenet')\n",
    "\n",
    "output=base_model.output #add new layers to the model\n",
    "output=GlobalAveragePooling2D()(output) #adds global average poolinglayer\n",
    "output=Dense(1024,activation='relu')(output)  #adds dense layer\n",
    "predictions = Dense(VGG_training_data_generator.num_classes,activation='softmax')(output)\n",
    "model = Model(inputs=base_model.input,outputs=predictions) \n",
    "\n",
    "for layer in base_model.layers: #freezes all of the weights in the base_model layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy') \n",
    "model.fit(VGG_training_data_generator,epochs=10,validation_data = VGG_validation_data_generator) # trains the newly added layers\n",
    "model.save('Models\\\\VGG.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f50305a9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d614910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    }
   ],
   "source": [
    "samples = len(VGG_testing_data_generator)\n",
    "predicted = []\n",
    "actual=[]\n",
    "#print(testing_data_generator.class_indices)\n",
    "for i in range(samples): #runs each sample in the test set\n",
    "    x,y=VGG_testing_data_generator.next() #x is the image and y is the label\n",
    "    predicted.append((model.predict(x)))\n",
    "    actual.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43258bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willi\\PycharmProjects\\ParcelClassification\\ParcelClassification.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m predicted_class \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39margmax() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m predicted]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m actual_class \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39margmax() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m actual]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willi/PycharmProjects/ParcelClassification/ParcelClassification.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m conf_matrix \u001b[39m=\u001b[39m confusion_matrix(actual_class, predicted_class) \u001b[39m#creates confusion matrix from predictions and actuals\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predicted_class = [i.argmax() for i in predicted]\n",
    "actual_class = [i.argmax() for i in actual]\n",
    "\n",
    "conf_matrix = confusion_matrix(actual_class, predicted_class) #creates confusion matrix from predictions and actuals\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Actual label', fontsize=18)\n",
    "plt.ylabel('Predicted label', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "precision = (conf_matrix[0][0])/(conf_matrix[0][0]+conf_matrix[0][1])\n",
    "recall = (conf_matrix[0][0])/(conf_matrix[0][0]+conf_matrix[1][0])\n",
    "\n",
    "print(\"Accuracy:\",  (conf_matrix[0][0]+conf_matrix[1][1])/((conf_matrix[0][0]+conf_matrix[0][1])+(conf_matrix[1][0]+conf_matrix[1][1])))\n",
    "print(\"Precision:\",  precision)\n",
    "print(\"Recall:\",  recall)\n",
    "print(\"Specificity:\",  (conf_matrix[1][1])/(conf_matrix[1][1]+conf_matrix[0][1]))\n",
    "print(\"F1-Score:\",  (2*precision * recall)/(precision+recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb291d6f",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43b98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "start_folder = 'data/split data/'\n",
    "category = [\"test/\",\"train/\"]\n",
    "category = [\"test/\",\"train/\",\"val/\"]\n",
    "classification = [\"goodpackages\",\"badpackages\"]\n",
    "for type in category:\n",
    "    class_folder = start_folder + type\n",
    "    for class_type in classification:\n",
    "        folder = class_folder + class_type\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348d454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1870f1194fb5b3d43b6d32e845741389586dbe9c4e1e45e17e0f6602cfe22778"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
